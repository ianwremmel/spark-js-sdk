/*!
 * Copyright (c) 2015-2017 Cisco Systems, Inc. See LICENSE file.
 */

import AmpState from 'ampersand-state';

import {debounce, isBoolean, isObject} from 'lodash';
import {deprecated} from 'core-decorators';

import {
  acceptAnswer,
  boolToDirection,
  createOffer,
  end,
  ensureH264,
  getUserMedia
} from './webrtc';

/**
 * Determines if the peer connection is receiving the specified kind of media
 * @param {string} kind audio|video
 * @param {RTCPeerConnection} pc
 * @private
 * @returns {bool} true if receiving, false if not
 */
function getRemoteMediaStatus(kind, pc) {
  if (pc.signalingState === `closed`) {
    return false;
  }

  const streams = pc.getRemoteStreams();

  if (streams.length === 0) {
    return false;
  }

  const res = streams.reduce((areStreamsFlowing, stream) => {
    const tracks = stream.getTracks().filter((track) => track.kind === kind);

    if (tracks.length === 0) {
      return false;
    }

    return tracks.reduce((isTrackReceiving, track) => {
      if (isTrackReceiving) {
        return isTrackReceiving;
      }

      if (track.readyState === `ended`) {
        return false;
      }

      if (track.ended) {
        return false;
      }

      return true;
    }, undefined);
  }, undefined);

  if (res) {
    return res;
  }

  return false;
}

/**
 * Determines if the peer connection is sending the specified kind of media
 * @param {string} kind audio|video
 * @param {RTCPeerConnection} pc
 * @private
 * @returns {bool} true if sending, false if not
 */
function getLocalMediaStatus(kind, pc) {
  // return pc.getSenders()
  //   .filter((s) => s.track.kind === kind)
  //   .reduce((acc, s) => acc || s.track.enabled, false);


  const res = pc.getLocalStreams().reduce((isFlowing, stream) => {
    const isStreamFlowing = stream.getTracks().reduce((isFlowingForTracks, track) => {
      const isTrackFlowing = track.kind === kind && track.enabled;
      return isFlowingForTracks || isTrackFlowing;
    }, false);
    return isFlowing || isStreamFlowing;
  }, false);
  return res;
}

const WebRTCMedia = AmpState.extend({
  props: {
    audio: {
      default: false,
      type: `boolean`
    },
    audioConstraint: `any`,
    bandwidthLimit: {
      type: `object`
    },
    ended: {
      default: false,
      type: `boolean`
    },
    localMediaStream: {
      default() {
        return new MediaStream();
      },
      type: `object`
    },
    offerToReceiveAudio: {
      default: false,
      type: `boolean`
    },
    offerToReceiveVideo: {
      default: false,
      type: `boolean`
    },
    receivingAudio: {
      default: false,
      type: `boolean`
    },
    receivingVideo: {
      default: false,
      type: `boolean`
    },
    remoteMediaStream: {
      default() {
        return new MediaStream();
      },
      type: `object`
    },
    sendingAudio: {
      default: false,
      type: `boolean`
    },
    sendingVideo: {
      default: false,
      type: `boolean`
    },
    video: {
      default: false,
      type: `boolean`
    },
    videoConstraint: `any`
  },

  session: {
    answerSdp: `string`,
    logger: {
      default() {
        return console;
      },
      type: `object`
    },
    offerSdp: `string`,
    pc: {
      default() {
        return new RTCPeerConnection({iceServers: []});
      },
      type: `object`
    }
  },

  derived: {
    audioDirection: {
      deps: [
        `sendingAudio`,
        `receivingAudio`
      ],
      fn() {
        return boolToDirection(this.sendingAudio, this.receivingAudio);
      }
    },
    videoDirection: {
      deps: [
        `sendingVideo`,
        `receivingVideo`
      ],
      fn() {
        return boolToDirection(this.sendingVideo, this.receivingVideo);
      }
    }
  },

  acceptAnswer(answer) {
    return acceptAnswer(this.pc, answer)
      .then(() => {
        this.answerSdp = answer;
        this.set({
          sendingAudio: getLocalMediaStatus(`audio`, this.pc),
          sendingVideo: getLocalMediaStatus(`video`, this.pc),
          receivingAudio: getRemoteMediaStatus(`audio`, this.pc),
          receivingVideo: getRemoteMediaStatus(`video`, this.pc)
        });
      })
      .then(() => this.trigger(`answeraccepted`));
  },

  addOrReplaceTrack(track) {
    this.logger.info(`preparing to add ${track.kind} to local media stream`);
    const existing = this.pc.getSenders().find((s) => s.track.kind === track.kind && s.track !== track);
    if (existing) {
      const originalTrack = existing.track;

      this.logger.info(`removing previous ${track.kind} track from local media stream`);
      this.localMediaStream.removeTrack(existing.track);

      this.logger.info(`adding next ${track.kind} track to local media stream`);
      this.localMediaStream.addTrack(track);

      if (existing.replaceTrack) {
        this.logger.info(`replacing ${track.kind} sender's track`);
        existing.replaceTrack(track);
      }
      else {
        this.pc.removeTrack(existing);
        this.pc.addTrack(track, this.localMediaStream);
      }
      this.logger.info(`stopping original ${track.kind} track`);
      originalTrack.stop();
    }
    else {
      // Reminder: to satisfy chromeshim, we need to add the track to the stream
      // before the stream with the track in it gets passed to pc.addTrack
      this.logger.info(`adding next ${track.kind} track to local media stream`);
      this.localMediaStream.addTrack(track);

      this.logger.info(`adding ${track.kind} to peer connection`);
      this.pc.addTrack(track, this.localMediaStream);
    }
  },

  createOffer() {
    let p;
    const needsAudio = this.audio && !this.pc.getSenders().find((s) => s.track.kind === `audio`);
    const needsVideo = this.video && !this.pc.getSenders().find((s) => s.track.kind === `video`);

    if (needsAudio || needsVideo) {
      p = Promise.resolve(WebRTCMedia.getUserMedia({
        audio: needsAudio && this.audioConstraint,
        video: needsVideo && this.videoConstraint
      })
        .then((stream) => {
          stream.getTracks().forEach((t) => {
            stream.removeTrack(t);
            this.addOrReplaceTrack(t);
          });
        }));
    }

    return Promise.resolve(p)
      .then(() => createOffer(this.pc, {
        offerToReceiveAudio: this.offerToReceiveAudio,
        offerToReceiveVideo: this.offerToReceiveVideo
      }, this.bandwidthLimit))
      .then(ensureH264(this.video))
      .then((sdp) => {
        this.bindNegotiationEvents();
        this.offerSdp = sdp;
        return sdp;
      });
  },

  @deprecated
  stop() {
    return this.end();
  },

  end() {
    if (!this.ended) {
      if (this.pc && this.pc.signalingState !== `closed`) {
        end(this.pc);
      }
      this.unset(`localMediaStream`);
      this.unset(`remoteMediaStream`);
      this.ended = true;
    }
  },

  initialize(...args) {
    Reflect.apply(AmpState.prototype.initialize, this, args);

    this.pc.ontrack = (event) => {
      this.trigger(`track`);
      event.streams[0]
        .getTracks()
        .forEach((track) => {
          this.remoteMediaStream.addTrack(track);
          track.onended = () => {
            this.remoteMediaStream.removeTrack(track);
            track.onended = undefined;
          };
        });

      // TODO need keep receivingAudio and receivingVideo up to date
    };


    [
      `audio`,
      `video`
    ].forEach((kind) => {
      this.on(`change:${kind}`, () => {
        if (!this.answerSdp) {
          return;
        }

        Promise.resolve(this[kind] ? this._startSendingMedia(kind) : this._stopSendingMedia(kind))
          .then(() => {
            this.set({
              sendingAudio: getLocalMediaStatus(`kind`, this.pc)
            });
          });
      });


      const offerKind = `offerToRecieve${kind === `audio` ? `Audio` : `Video`}`;
      this.on(`change:${offerKind}`, () => {
        if (!this.answerSdp) {
          return;
        }

        if (this[offerKind]) {
          if (this.remoteMediaStream.getTracks().find((t) => t.kind === kind)) {
            this.unpauseReceivingMedia(kind);
          }
          else {

          }
        }
        else {
          this.pauseReceivingMedia(kind);
        }
      });
    });

    // this.on(`change:localMediaStream`, () => {
    //   if (!this.pc) {
    //     return;
    //   }

    //   if (this.pc.signalingState === `closed`) {
    //     return;
    //   }

    //   const streams = this.pc.getLocalStreams();
    //   if (!streams.includes(this.localMediaStream)) {
    //     streams.forEach((stream) => {
    //       removeStream(this.pc, stream);
    //     });
    //     addStream(this.pc, this.localMediaStream);

    //     const sendingAudio = getLocalMediaStatus(`audio`, this.pc);
    //     const sendingVideo = getLocalMediaStatus(`video`, this.pc);
    //     this.set({
    //       sendingAudio,
    //       audio: sendingAudio,
    //       sendingVideo,
    //       video: sendingVideo
    //     });
    //   }
    // });
  },

  pauseReceivingMedia(kind) {
    if (!kind) {
      throw new Error(`kind is required`);
    }

    const tracks = this.remoteMediaStream
      .getTracks()
      .filter((t) => t.kind === kind);

    if (tracks.length === 0) {
      throw new Error(`No remote ${kind} media tracks to pause`);
    }

    tracks.forEach((t) => {
      this.logger.info(`pausing remote ${kind} track`);
      t.enabled = false;
    });
  },

  unpauseReceivingMedia(kind) {
    if (!kind) {
      throw new Error(`kind is required`);
    }

    const tracks = this.remoteMediaStream
      .getTracks()
      .filter((t) => t.kind === kind);

    if (tracks.length === 0) {
      throw new Error(`No remote ${kind} media tracks to unpause`);
    }

    tracks.forEach((t) => {
      this.logger.info(`unpausing remote ${kind} track`);
      t.enabled = true;
    });
  },

  /**
   * Binds events that should be bound one time only once the session has been
   * fully negotiated
   * @private
   * @returns {undefined}
   */
  bindNegotiationEvents() {
    if (this.bound) {
      return;
    }
    this.bound = true;

    this.pc.onnegotiationneeded = debounce(() => {
      this.emit(`negotiationneeded`);
    });

    this.on(`change:offerToReceiveAudio`, () => {
      this.trigger(`negotiationneeded`);
    });

    this.on(`change:offerToReceiveVideo`, () => {
      this.trigger(`negotiationneeded`);
    });
  },

  set(key, value, options) {
    let attrs;
    // Handle both `"key", value` and `{key: value}` -style arguments.
    if (isObject(key) || key === null) {
      attrs = key;
      options = value;
    }
    else {
      attrs = {};
      attrs[key] = value;
    }

    options = options || {};

    Object.keys(attrs).forEach((k) => {
      [`audio`, `video`].forEach((mediaType) => {
        if (k === mediaType) {
          if (isObject(attrs[k])) {
            attrs[`${mediaType}Constraint`] = attrs[k];
            attrs[k] = true;
          }
          else if (isBoolean(attrs[k])) {
            attrs[`${mediaType}Constraint`] = attrs[k];
          }
        }
      });
    });

    Reflect.apply(AmpState.prototype.set, this, [attrs, options]);
  },

  _startSendingMedia(kind) {
    let expectNegotiation = false;
    const sender = this.pc.getSenders().find((s) => s.track.kind === `kind`);
    if (sender) {
      sender.track.enabled = true;
    }
    else {
      expectNegotiation = true;
      const constraints = {
        audio: kind === `audio`,
        video: kind === `video`
      };

      getUserMedia(constraints)
        .then((stream) => {
          const track = stream.getTracks().find((t) => t.kind === kind);
          this.addOrReplaceTrack(track);
        });
    }

    if (expectNegotiation) {
      return new Promise((resolve) => {
        this.once(`negotiationneeded`, () => {
          this.once(`answeraccepted`, resolve);
        });
      });
    }

    return Promise.resolve();

  },

  _stopSendingMedia(kind) {
    let expectNegotiation = false;
    this.logger.info(`removing any no-longer-needed ${kind} tracks`);
    this.localMediaStream
      .getTracks()
      .filter((t) => t.kind === kind)
      .forEach((t) => {
        expectNegotiation = true;
        this.logger.info(`stopping ${kind} track ${t.id}`);
        t.stop();
        this.logger.info(`removing ${kind} track ${t.id} from localMediaStream`);
        this.localMediaStream.removeTrack(t);
        // if (this.pc.removeTrack) {
        this.logger.info(`removing ${kind} track ${t.id} from peer connection`);
        this.pc.removeTrack(this.pc.getSenders().find((s) => s.track === t));
        // }
        // else {
        //   this.pc.getLocalStreams().forEach((stream) => {
        //     this.logger.info(`removing ${kind} track ${t.id} from peer connection stream ${stream.id}`);
        //     stream.removeTrack(t);
        //   });
        // }
      });

    if (expectNegotiation) {
      return new Promise((resolve) => {
        this.once(`negotiationneeded`, () => {
          this.once(`answeraccepted`, resolve);
        });
      });
    }

    return Promise.resolve();

  }
});

WebRTCMedia.getUserMedia = getUserMedia;

export default WebRTCMedia;
