import AmpState from 'ampersand-state';

import {debounce, isBoolean, isObject} from 'lodash';

import {
  acceptAnswer,
  addStream,
  createOffer,
  end,
  ensureH264,
  getUserMedia,
  removeStream,
  getLocalMediaStatus,
  getRemoteMediaStatus,
  sending
} from './webrtc';

const WebRTCMedia = AmpState.extend({
  props: {
    audio: {
      default: false,
      type: `boolean`
    },
    audioConstraint: `any`,
    ended: {
      default: false,
      type: `boolean`
    },
    localMediaStream: {
      default: undefined,
      type: `object`
    },
    offerToReceiveAudio: {
      default: false,
      type: `boolean`
    },
    offerToReceiveVideo: {
      default: false,
      type: `boolean`
    },
    receivingAudio: {
      default: false,
      type: `boolean`
    },
    receivingVideo: {
      default: false,
      type: `boolean`
    },
    remoteMediaStream: {
      default: undefined,
      type: `object`
    },
    sendingAudio: {
      default: false,
      type: `boolean`
    },
    sendingVideo: {
      default: false,
      type: `boolean`
    },
    video: {
      default: false,
      type: `boolean`
    },
    videoConstraint: `any`
  },

  session: {
    answerSdp: `string`,
    offerSdp: `string`,
    peer: {
      type: `object`
    }
  },

  acceptAnswer(answer) {
    return acceptAnswer(this.peer, answer)
      .then(() => {
        this.answerSdp = answer;
        this.set({
          sendingAudio: getLocalMediaStatus(`audio`, this.peer),
          sendingVideo: getLocalMediaStatus(`video`, this.peer)
        });
      })
      .then(() => this.trigger(`answeraccepted`));
  },

  createOffer() {
    if (!this.peer) {
      this.peer = new RTCPeerConnection({iceServers: []});
      this.remoteMediaStream = new MediaStream();

      this.peer.ontrack = (event) => {
        const stream = event.streams[0];
        stream.getTracks().forEach((track) => this.remoteMediaStream.addTrack(track));

        stream.getTracks().forEach((track) => {
          track.onended = () => {
            try {
              if (track.kind === `audio`) {
                this.receivingAudio = getRemoteMediaStatus(`audio`, this.peer);
              }
              else {
                this.receivingVideo = getRemoteMediaStatus(`video`, this.peer);
              }
            }
            catch (e) {
              this.emit(`error`, e);
            }
          };
        });

        this.receivingAudio = getRemoteMediaStatus(`audio`, this.peer);
        this.receivingVideo = getRemoteMediaStatus(`video`, this.peer);
      };
    }

    let p;
    if (this.localMediaStream) {
      p = Promise.resolve();
    }
    else if (this.audio || this.video) {
      p = Promise.resolve(getUserMedia({
        audio: this.audioConstraint,
        video: this.videoConstraint
      })
        .then((stream) => {
          if (!this.localMediaStream) {
            this.localMediaStream = new MediaStream();
          }
          stream.getTracks().forEach((track) => this.localMediaStream.addTrack(track));
        }));
    }

    return Promise.resolve(p)
      // .then(() => {
      //
      //   // if (this.localMediaStream && !this.peer.getLocalStreams().includes(this.localMediaStream)) {
      //   //   addStream(this.peer, this.localMediaStream);
      //   // }
      // })
      .then(() => createOffer(this.peer, {
        offerToReceiveAudio: this.offerToReceiveAudio,
        offerToReceiveVideo: this.offerToReceiveVideo
      }))
      .then(ensureH264(this.video))
      .then((sdp) => {
        this.bindNegotiationEvents();
        this.offerSdp = sdp;
        return sdp;
      });
  },

  end() {
    if (!this.ended) {
      if (this.peer && this.peer.signalingState !== `closed`) {
        end(this.peer);
      }
      this.unset(`localMediaStream`);
      this.unset(`remoteMediaStream`);
      this.ended = true;
    }
  },

  initialize(...args) {
    Reflect.apply(AmpState.prototype.initialize, this, args);

    [
      `audio`,
      `video`
    ].forEach((mediaType) => {
      this.on(`change:${mediaType}`, () => {
        if (!this.peer) {
          return;
        }

        let p;
        if (this[mediaType]) {
          const hasTrack = this.localMediaStream
            .getTracks()
            // I really don't see a more readable way to implement this
            // eslint-disable-next-line max-nested-callbacks
            .filter((track) => track.kind === mediaType)
            .length;

          if (hasTrack) {
            p = sending[mediaType].start(this.peer);
          }
          else {
            p = new Promise((resolve) => {
              // I really don't see a more readable way to implement this
              // eslint-disable-next-line max-nested-callbacks
              this.once(`negotiationneeded`, () => {
                this.once(`answeraccepted`, resolve);
              });
            });
            sending[mediaType].start(this.peer);
          }
        }
        else {
          p = sending[mediaType].stop(this.peer);
        }

        Promise.resolve(p)
          .then(() => {
            this[mediaType === `audio` ? `sendingAudio` : `sendingVideo`] = getLocalMediaStatus(mediaType, this.peer);
          })
          .catch((reason) => {
            this.emit(`error`, reason);
          });
      });

    });

    // this.on(`change:localMediaStream`, () => {
    //   if (!this.peer) {
    //     return;
    //   }
    //
    //   if (this.peer.signalingState === `closed`) {
    //     return;
    //   }
    //
    //   const streams = this.peer.getLocalStreams();
    //   if (!streams.includes(this.localMediaStream)) {
    //     streams.forEach((stream) => {
    //       removeStream(this.peer, stream);
    //     });
    //     addStream(this.peer, this.localMediaStream);
    //
    //     const sendingAudio = getLocalMediaStatus(`audio`, this.peer);
    //     const sendingVideo = getLocalMediaStatus(`video`, this.peer);
    //     this.set({
    //       sendingAudio,
    //       audio: sendingAudio,
    //       sendingVideo,
    //       video: sendingVideo
    //     });
    //   }
    // });
  },

  /**
   * Binds events that should be bound one time only once the session has been
   * fully negotiated
   * @private
   * @returns {undefined}
   */
  bindNegotiationEvents() {
    if (this.bound) {
      return;
    }
    this.bound = true;

    this.peer.onnegotiationneeded = debounce(() => {
      this.emit(`negotiationneeded`);
    });

    this.on(`change:offerToReceiveAudio`, () => {
      this.trigger(`negotiationneeded`);
    });

    this.on(`change:offerToReceiveVideo`, () => {
      this.trigger(`negotiationneeded`);
    });
  },

  set(key, value, options) {
    let attrs;
    // Handle both `"key", value` and `{key: value}` -style arguments.
    if (isObject(key) || key === null) {
      attrs = key;
      options = value;
    }
    else {
      attrs = {};
      attrs[key] = value;
    }

    options = options || {};

    Object.keys(attrs).forEach((k) => {
      [`audio`, `video`].forEach((mediaType) => {
        if (k === mediaType) {
          if (isObject(attrs[k])) {
            attrs[`${mediaType}Constraint`] = attrs[k];
            attrs[k] = true;
          }
          else if (isBoolean(attrs[k])) {
            attrs[`${mediaType}Constraint`] = attrs[k];
          }
        }
      });
    });

    Reflect.apply(AmpState.prototype.set, this, [attrs, options]);
  }

});

export default WebRTCMedia;
